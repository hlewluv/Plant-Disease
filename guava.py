# -*- coding: utf-8 -*-
"""guava.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/Annguyn/plant-detective/blob/main/guava.ipynb
"""

from google.colab import drive
drive.mount('/content/drive')

# !unzip '/content/drive/MyDrive/Colab Notebooks/dataset_guav.zip' -d '/content/drive/MyDrive/Colab Notebooks/'

import tensorflow as tf
from tensorflow.keras import models, layers
import matplotlib.pyplot as plt

IMAGE_SIZE_X = 224
IMAGE_SIZE_Y = 224
NUM_CLASSES = 3
CHANNELS=3
EPOCHS=50

train_dir = "/content/drive/MyDrive/Colab Notebooks/Guava+dataset/train"
valid_dir = "/content/drive/MyDrive/Colab Notebooks/Guava+dataset/val"
test_dir = "/content/drive/MyDrive/Colab Notebooks/Guava+dataset/test"

from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.3,
    height_shift_range=0.3,
    shear_range=0.3,
    zoom_range=0.3,
    horizontal_flip=True,
    fill_mode='nearest'
)

train_data = datagen.flow_from_directory(
    train_dir,
    target_size=(IMAGE_SIZE_X, IMAGE_SIZE_Y),
    batch_size=16,
    class_mode='categorical'
)

import tensorflow as tf

IMG_SIZE = (IMAGE_SIZE_X, IMAGE_SIZE_Y)
BATCH_SIZE = 16

test_data = tf.keras.preprocessing.image_dataset_from_directory(
    directory = test_dir,
    image_size = IMG_SIZE,
    label_mode = 'categorical',
    batch_size = BATCH_SIZE
).cache().prefetch(buffer_size=tf.data.AUTOTUNE)

valid_datasets = tf.keras.preprocessing.image_dataset_from_directory(
    directory = valid_dir,
    image_size = IMG_SIZE,
    label_mode = 'categorical',
    batch_size = BATCH_SIZE
)

class_names = valid_datasets.class_names
valid_data = valid_datasets.cache().prefetch(buffer_size=tf.data.AUTOTUNE)

print(class_names)

import numpy as np

plt.figure(figsize=(10, 10))

image_batch, label_batch = next(train_data)

for i in range(min(12, len(image_batch))):
    plt.subplot(3, 4, i + 1)
    plt.imshow(image_batch[i].astype("uint32"))
    plt.title(class_names[np.argmax(label_batch[i])])
    plt.axis("off")



import matplotlib.pyplot as plt
import numpy as np

def count_images_per_class(directory):
    class_counts = {}
    for class_name in class_names:
        class_dir = os.path.join(directory, class_name)
        if os.path.isdir(class_dir):
            class_counts[class_name] = len(os.listdir(class_dir))
    return class_counts


import os
train_counts = count_images_per_class(train_dir)
valid_counts = count_images_per_class(valid_dir)
test_counts = count_images_per_class(test_dir)

print("Training Set:")
for class_name, count in train_counts.items():
    print(f"  {class_name}: {count} images")

print("\nValidation Set:")
for class_name, count in valid_counts.items():
    print(f"  {class_name}: {count} images")

print("\nTest Set:")
for class_name, count in test_counts.items():
    print(f"  {class_name}: {count} images")

from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam

base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE_X, IMAGE_SIZE_Y, 3))

for layer in base_model.layers:
    layer.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(3, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)

model.compile(optimizer=Adam(learning_rate=0.0001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

import os

for class_name in class_names:
  class_dir = os.path.join(train_dir, class_name) #
  num_images = len(os.listdir(class_dir))
  print(f"Class: {class_name}, Number of images: {num_images}")



checkpoint_path = "CheckPoint/cp.ckpt.weights.h5"
checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    checkpoint_path,
    save_weights_only=True,
    monitor='val_accuracy',
    save_best_only=True
)



history = model.fit(
    train_data,
    epochs=100,
    validation_data=test_data,
    callbacks=[
        checkpoint_callback,
    ]
)

# scores = model.evaluate(test_ds)

# scores

history

history.params

history.history.keys()

type(history.history['loss'])

len(history.history['loss'])

history.history['loss'][:5]

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(range(len(acc)), acc, label='Training Accuracy')
plt.plot(range(len(val_acc)), val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(range(len(loss)), loss, label='Training Loss')
plt.plot(range(len(val_loss)), val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

from google.colab import files
uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))


import tensorflow as tf

img = tf.keras.preprocessing.image.load_img(fn, target_size=(224, 224))
x = tf.keras.preprocessing.image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = data_augmentation(x)

images = np.vstack([x])
classes = model.predict(images, batch_size=10)
classes

model.save('guava_model.keras')

test_dir = "/content/drive/MyDrive/Colab Notebooks/Guava+dataset/test"
class_names = ['dot', 'healthy',  'rust']

for class_name in class_names:
    class_dir = os.path.join(test_dir, class_name)
    for image_name in os.listdir(class_dir):
        image_path = os.path.join(class_dir, image_name)

        img = tf.keras.utils.load_img(image_path, target_size=(224, 224))
        img_array = tf.keras.utils.img_to_array(img)
        img_array = tf.expand_dims(img_array, 0)

        prediction = model.predict(img_array)
        predicted_class = class_names[np.argmax(prediction[0])]

        print(f"Image: {image_name}")
        print(f"Actual Class: {class_name}")
        print(f"Predicted Class: {predicted_class}")
        print("-" * 30)

from google.colab import files
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt


class_names = ['dot', 'healthy', 'rust']
uploaded = files.upload()

for fn in uploaded.keys():
    path = '/content/' + fn
    img = tf.keras.utils.load_img(path, target_size=(224, 224))
    img_array = tf.keras.utils.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)

    prediction = model.predict(img_array)
    predicted_class = class_names[np.argmax(prediction[0])]
    confidence = round(100 * (np.max(prediction[0])), 2)

    print(f"Image: {fn}")
    print(f"Predicted class: {predicted_class}")
    print(f"Confidence: {confidence}%")

    plt.imshow(img)
    plt.title(f"Predicted: {predicted_class}, Confidence: {confidence}%")
    plt.axis("off")
    plt.show()

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
import numpy as np
import os
import pandas as pd
from tensorflow.keras.preprocessing import image

model = tf.keras.models.load_model('/content/guava_model.keras')

test_dir = "/content/drive/MyDrive/Colab Notebooks/test_data"
class_names = ['dot', 'healthy', 'rust']

correct_predictions = 0
total_predictions = 0

results = []

for class_name in class_names:
    class_dir = os.path.join(test_dir, class_name)
    for image_name in os.listdir(class_dir):
        image_path = os.path.join(class_dir, image_name)

        img = tf.keras.utils.load_img(image_path, target_size=(224, 224))
        img_array = tf.keras.utils.img_to_array(img)
        img_array = tf.expand_dims(img_array, 0)

        prediction = model.predict(img_array)
        confidence = np.max(prediction[0])
        predicted_class = class_names[np.argmax(prediction[0])]

        total_predictions += 1
        if predicted_class == class_name:
            correct_predictions += 1

        results.append({
            "Image Name": image_name,
            "Predicted Class": predicted_class,
            "Actual Class": class_name,
            "Confidence": confidence
        })

accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0

results_df = pd.DataFrame(results)
print(results_df)

results_df.to_csv('/content/prediction_results.csv', index=False)

print(f"Test Accuracy: {accuracy * 100:.2f}%")

import tensorflow as tf
import numpy as np
import os
import pandas as pd
from tensorflow.keras.preprocessing import image

model = tf.keras.models.load_model('/content/guava_model.keras')

test_dir = "/content/drive/MyDrive/Colab Notebooks/guava-image"
class_names = ['dot', 'healthy', 'rust']

correct_predictions = 0
total_predictions = 0

results = []

for class_name in class_names:
    class_dir = os.path.join(test_dir, class_name)
    for image_name in os.listdir(class_dir):
        image_path = os.path.join(class_dir, image_name)

        img = tf.keras.utils.load_img(image_path, target_size=(224, 224))
        img_array = tf.keras.utils.img_to_array(img)
        img_array = tf.expand_dims(img_array, 0)

        prediction = model.predict(img_array)
        confidence = np.max(prediction[0])
        predicted_class = class_names[np.argmax(prediction[0])]

        total_predictions += 1
        if predicted_class == class_name:
            correct_predictions += 1

        results.append({
            "Image Name": image_name,
            "Predicted Class": predicted_class,
            "Actual Class": class_name,
            "Confidence": confidence
        })

accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0
results_df = pd.DataFrame(results)
print(results_df)

results_df.to_csv('/content/predict_result_2.csv', index=False)

print(f"Test Accuracy: {accuracy * 100:.2f}%")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/prediction_results.csv')

print(df.head())

plt.figure(figsize=(8, 6))
sns.countplot(x='Predicted Class', data=df)
plt.title('Distribution of Predicted Classes')
plt.xlabel('Predicted Class')
plt.ylabel('Count')
plt.show()

plt.figure(figsize=(8, 6))
sns.countplot(x='Actual Class', data=df)
plt.title('Distribution of Actual Classes')
plt.xlabel('Actual Class')
plt.ylabel('Count')
plt.show()


accuracy_by_class = df.groupby('Actual Class').apply(lambda x: (x['Predicted Class'] == x['Actual Class']).sum() / len(x))
print("\nAccuracy by Class:")
print(accuracy_by_class)

plt.figure(figsize=(8, 6))
sns.barplot(x=accuracy_by_class.index, y=accuracy_by_class.values)
plt.title('Accuracy by Class')
plt.xlabel('Class')
plt.ylabel('Accuracy')
plt.show()


plt.figure(figsize=(10, 6))
sns.scatterplot(x='Confidence', y='Actual Class', data=df, hue='Predicted Class')
plt.title('Confidence vs. Actual Class')
plt.xlabel('Confidence')
plt.ylabel('Actual Class')
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns

conf_matrix = confusion_matrix(df['Actual Class'], df['Predicted Class'])

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Class')
plt.ylabel('Actual Class')
plt.show()

import tensorflow as tf
import numpy as np
import os
import pandas as pd
from openpyxl import Workbook
from openpyxl.drawing.image import Image as OpenpyxlImage
from openpyxl.utils import get_column_letter

model = tf.keras.models.load_model('/content/guava_model.keras')

test_dir = "/content/drive/MyDrive/Colab Notebooks/test_data"
class_names = ['dot', 'healthy', 'rust']

correct_predictions = 0
total_predictions = 0

results = []

for class_name in class_names:
    class_dir = os.path.join(test_dir, class_name)
    for image_name in os.listdir(class_dir):
        image_path = os.path.join(class_dir, image_name)

        img = tf.keras.utils.load_img(image_path, target_size=(224, 224))
        img_array = tf.keras.utils.img_to_array(img)
        img_array = tf.expand_dims(img_array, 0)

        prediction = model.predict(img_array)
        confidence = np.max(prediction[0])
        predicted_class = class_names[np.argmax(prediction[0])]

        total_predictions += 1
        if predicted_class == class_name:
            correct_predictions += 1

        results.append({
            "Image Name": image_name,
            "Predicted Class": predicted_class,
            "Actual Class": class_name,
            "Confidence": confidence,
            "Image Path": image_path
        })

accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0

results_df = pd.DataFrame(results)

output_file = "/content/prediction_results_with_images.xlsx"
wb = Workbook()
ws = wb.active
ws.title = "Results"

headers = ["Image Name", "Predicted Class", "Actual Class", "Confidence", "Image"]
ws.append(headers)

for idx, row in results_df.iterrows():
    ws.append([row["Image Name"], row["Predicted Class"], row["Actual Class"], row["Confidence"]])
    img = OpenpyxlImage(row["Image Path"])
    img.height = 80
    img.width = 80
    image_cell = f"E{idx + 2}"
    ws.add_image(img, image_cell)

for col_idx, column_cells in enumerate(ws.columns, start=1):
    max_length = max((len(str(cell.value)) for cell in column_cells if cell.value), default=0)
    ws.column_dimensions[get_column_letter(col_idx)].width = max_length + 2

wb.save(output_file)

print(f"Test Accuracy: {accuracy * 100:.2f}%")
print(f"Results with images saved to {output_file}")